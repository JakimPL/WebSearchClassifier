dataset:
  path: data/train.csv
  extension: .csv
  prompt_column: prompt
  label_column: search
  confidence_column: confidence

output_directory: models/

general:
  device: &device auto
  random_state: &random_state 42
  batch_size: &batch_size 128

baselines:
  tfidf:
    max_features: 5000
    ngram_range: [1, 3]
    min_document_frequency: 2
    max_document_frequency: 0.95

  fasttext:
    embedding_dim: 300
    embeddings_path: cc.pl.300.bin

  herbert:
    model_name: allegro/herbert-base-cased
    batch_size: *batch_size
    device: *device

classifiers:
  logistic_regression:
    random_state: *random_state
    max_iterations: 1000
    regularization_strength: 1.0

  mlp:
    random_state: *random_state
    hidden_layer_sizes: [128, 64]
    activation: tanh
    learning_rate: 0.001
    max_iterations: 200
    batch_size: *batch_size
    dropout_rate: 0.3
    early_stopping: true
    validation_fraction: 0.1

  svm:
    random_state: *random_state
    regularization_strength: 1.0
    probability: true
    kernel: rbf
